{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d5133a-b73b-45d2-8e4b-a30205845fb1",
   "metadata": {},
   "source": [
    "This notebook **FeatureEngineering_and_Train.ipynb** performs \n",
    "- preprocessing,\n",
    "- feature engineering,\n",
    "- train-test split,\n",
    "- scaling,\n",
    "- model training (Logistic Regression + Random Forest), and\n",
    "- saves the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60828bdb-1473-4c01-8e07-0234ce62dd69",
   "metadata": {},
   "source": [
    "#### **üßæ 1. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6f8ae0-bbc5-4c96-a136-52bf78f93e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn modules for preprocessing, modeling, and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf86cfc-c08f-4fa2-8d28-bad040ed1d77",
   "metadata": {},
   "source": [
    "#### **üìÇ 2. Load Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f2d980-7a3e-4100-bf87-298d7997a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-cleaned dataset\n",
    "df = pd.read_csv('../../data/processed/cleaned_fraud_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88a020-d7e1-496b-90d8-f194d5700c89",
   "metadata": {},
   "source": [
    "#### **üõ†Ô∏è 3. Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f17466-9fd9-41b5-9db5-9f537826396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time fields to datetime objects\n",
    "df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "\n",
    "# Create a feature for time difference between signup and purchase\n",
    "df['signup_to_purchase_sec'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds()\n",
    "\n",
    "# Weekend flag based on the day of the week\n",
    "df['is_weekend'] = df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "# Nighttime flag: 1 if hour is before 6 AM or after 10 PM\n",
    "df['is_night'] = df['hour_of_day'].apply(lambda x: 1 if (x < 6 or x > 22) else 0)\n",
    "\n",
    "# IP range (helps in detecting dynamic/static IPs)\n",
    "df['ip_range'] = df['upper_bound_ip_address'] - df['lower_bound_ip_address']\n",
    "\n",
    "# Average time since signup per user\n",
    "avg_tx_time = df.groupby('user_id')['time_since_signup'].mean().rename(\"avg_tx_time_user\")\n",
    "df = df.merge(avg_tx_time, on='user_id', how='left')\n",
    "\n",
    "# Transaction density = count / time\n",
    "df['tx_density'] = df['transaction_count'] / (df['time_since_signup'] + 1e-6)\n",
    "\n",
    "# Encode browser frequency (rare/unknown browsers may indicate fraud)\n",
    "df['browser_freq'] = df['browser'].map(df['browser'].value_counts())\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "df = pd.get_dummies(df, columns=['source', 'sex'], drop_first=True)\n",
    "\n",
    "# Log transformations to reduce skew\n",
    "df['log_purchase_value'] = np.log1p(df['purchase_value'])\n",
    "df['log_tx_count'] = np.log1p(df['transaction_count'])\n",
    "\n",
    "# Drop irrelevant or redundant columns\n",
    "drop_cols = [\n",
    "    'signup_time', 'purchase_time', 'user_id', 'device_id', 'ip_address',\n",
    "    'country', 'browser', 'lower_bound_ip_address', 'upper_bound_ip_address',\n",
    "    'purchase_value', 'transaction_count'\n",
    "]\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Shuffle the dataset to randomize the order\n",
    "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the feature-engineered dataset\n",
    "os.makedirs(\"../../data/processed\", exist_ok=True)\n",
    "df.to_csv(\"../../data/processed/engineered_fraud_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ff94f-3fec-41a8-b8fb-8129dac98c10",
   "metadata": {},
   "source": [
    "#### **üßÆ 4. Prepare Features and Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d2acd3-9adc-4b20-ba18-f9d57e1531da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# Split into training and test sets (stratified for class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b334265-f330-402a-b4cc-db9e4dde007c",
   "metadata": {},
   "source": [
    "#### **‚öñÔ∏è 5. Scale Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679b3a69-6fe8-46f4-a9b3-3ae851b503c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/fraud_scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the fitted scaler for later use (e.g., inference pipeline)\n",
    "joblib.dump(scaler, \"../../models/fraud_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ab5ab-20a9-4197-bdec-c687864a21e4",
   "metadata": {},
   "source": [
    "#### **üìä 6. Train Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50b9a7e-e429-44f4-acb8-7f08487fcb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model with class balancing\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(lr_model, \"../../models/logistic_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9ef46-9206-4209-aabd-e2479ba4c9f2",
   "metadata": {},
   "source": [
    "#### **üå≤ 7. Train Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207d58a-8ab7-4cd3-a8a4-e4a57df296e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(rf_model, \"../../models/random_forest_model.pkl\", compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b138f-2fcc-4400-bb61-3f0806804949",
   "metadata": {},
   "source": [
    "#### **üìà 8. Model Evaluation (Validation Set)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c9cad9-17e5-422d-8b3e-928d05e83aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Logistic Regression\n",
      "F1 Score: 0.7043\n",
      "AUC-PR: 0.6424\n",
      "ROC AUC: 0.7787\n",
      "------------------------------\n",
      "üìå Random Forest\n",
      "F1 Score: 0.7043\n",
      "AUC-PR: 0.6319\n",
      "ROC AUC: 0.7666\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both models using F1 Score, AUC-PR, and ROC AUC\n",
    "models = {\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Random Forest\": rf_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_pr = average_precision_score(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(f\"üìå {name}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
